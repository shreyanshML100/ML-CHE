{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.precision\", 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-03-10</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1360.00</td>\n",
       "      <td>150</td>\n",
       "      <td>11.88</td>\n",
       "      <td>1045.50</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1056.25</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1692.00</td>\n",
       "      <td>1267.50</td>\n",
       "      <td>13.60</td>\n",
       "      <td>48.88</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-03-10</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1292.25</td>\n",
       "      <td>112</td>\n",
       "      <td>9.40</td>\n",
       "      <td>954.75</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1173.75</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1558.75</td>\n",
       "      <td>972.25</td>\n",
       "      <td>13.30</td>\n",
       "      <td>47.70</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-03-10</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1402.00</td>\n",
       "      <td>88</td>\n",
       "      <td>9.00</td>\n",
       "      <td>939.25</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1140.00</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1554.50</td>\n",
       "      <td>1074.00</td>\n",
       "      <td>11.90</td>\n",
       "      <td>53.98</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-03-10</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1375.50</td>\n",
       "      <td>80</td>\n",
       "      <td>9.23</td>\n",
       "      <td>948.25</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1092.00</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1583.75</td>\n",
       "      <td>1203.25</td>\n",
       "      <td>11.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-03-10</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1272.25</td>\n",
       "      <td>51</td>\n",
       "      <td>6.52</td>\n",
       "      <td>835.50</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1205.00</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1490.00</td>\n",
       "      <td>1110.00</td>\n",
       "      <td>11.15</td>\n",
       "      <td>59.58</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      Time  CO(GT)  PT08.S1(CO)  NMHC(GT)  C6H6(GT)  \\\n",
       "0 2004-03-10  18:00:00     2.6      1360.00       150     11.88   \n",
       "1 2004-03-10  19:00:00     2.0      1292.25       112      9.40   \n",
       "2 2004-03-10  20:00:00     2.2      1402.00        88      9.00   \n",
       "3 2004-03-10  21:00:00     2.2      1375.50        80      9.23   \n",
       "4 2004-03-10  22:00:00     1.6      1272.25        51      6.52   \n",
       "\n",
       "   PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)  \\\n",
       "0        1045.50    166.0       1056.25    113.0       1692.00      1267.50   \n",
       "1         954.75    103.0       1173.75     92.0       1558.75       972.25   \n",
       "2         939.25    131.0       1140.00    114.0       1554.50      1074.00   \n",
       "3         948.25    172.0       1092.00    122.0       1583.75      1203.25   \n",
       "4         835.50    131.0       1205.00    116.0       1490.00      1110.00   \n",
       "\n",
       "       T     RH    AH  \n",
       "0  13.60  48.88  0.76  \n",
       "1  13.30  47.70  0.73  \n",
       "2  11.90  53.98  0.75  \n",
       "3  11.00  60.00  0.79  \n",
       "4  11.15  59.58  0.79  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing=[pd.NA,(float)(-200),(int)(-200),-200]\n",
    "df= pd.read_excel(\"AirQualityUCI.xlsx\",na_values=missing)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9357, 15)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9357 entries, 0 to 9356\n",
      "Data columns (total 15 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   Date           9357 non-null   datetime64[ns]\n",
      " 1   Time           9357 non-null   object        \n",
      " 2   CO(GT)         7674 non-null   float64       \n",
      " 3   PT08.S1(CO)    8991 non-null   float64       \n",
      " 4   NMHC(GT)       9357 non-null   int64         \n",
      " 5   C6H6(GT)       8991 non-null   float64       \n",
      " 6   PT08.S2(NMHC)  8991 non-null   float64       \n",
      " 7   NOx(GT)        7718 non-null   float64       \n",
      " 8   PT08.S3(NOx)   8991 non-null   float64       \n",
      " 9   NO2(GT)        7715 non-null   float64       \n",
      " 10  PT08.S4(NO2)   8991 non-null   float64       \n",
      " 11  PT08.S5(O3)    8991 non-null   float64       \n",
      " 12  T              8991 non-null   float64       \n",
      " 13  RH             8991 non-null   float64       \n",
      " 14  AH             8991 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(12), int64(1), object(1)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                0\n",
       "Time                0\n",
       "CO(GT)           1683\n",
       "PT08.S1(CO)       366\n",
       "NMHC(GT)            0\n",
       "C6H6(GT)          366\n",
       "PT08.S2(NMHC)     366\n",
       "NOx(GT)          1639\n",
       "PT08.S3(NOx)      366\n",
       "NO2(GT)          1642\n",
       "PT08.S4(NO2)      366\n",
       "PT08.S5(O3)       366\n",
       "T                 366\n",
       "RH                366\n",
       "AH                366\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.drop(['CO(GT)','NOx(GT)','NO2(GT)','NMHC(GT)'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date             0\n",
       "Time             0\n",
       "PT08.S1(CO)      0\n",
       "C6H6(GT)         0\n",
       "PT08.S2(NMHC)    0\n",
       "PT08.S3(NOx)     0\n",
       "PT08.S4(NO2)     0\n",
       "PT08.S5(O3)      0\n",
       "T                0\n",
       "RH               0\n",
       "AH               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1==-200].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9357, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-03-10</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>1360.00</td>\n",
       "      <td>11.88</td>\n",
       "      <td>1045.50</td>\n",
       "      <td>1056.25</td>\n",
       "      <td>1692.00</td>\n",
       "      <td>1267.50</td>\n",
       "      <td>13.60</td>\n",
       "      <td>48.88</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-03-10</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>1292.25</td>\n",
       "      <td>9.40</td>\n",
       "      <td>954.75</td>\n",
       "      <td>1173.75</td>\n",
       "      <td>1558.75</td>\n",
       "      <td>972.25</td>\n",
       "      <td>13.30</td>\n",
       "      <td>47.70</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-03-10</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>1402.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>939.25</td>\n",
       "      <td>1140.00</td>\n",
       "      <td>1554.50</td>\n",
       "      <td>1074.00</td>\n",
       "      <td>11.90</td>\n",
       "      <td>53.98</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-03-10</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>1375.50</td>\n",
       "      <td>9.23</td>\n",
       "      <td>948.25</td>\n",
       "      <td>1092.00</td>\n",
       "      <td>1583.75</td>\n",
       "      <td>1203.25</td>\n",
       "      <td>11.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-03-10</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>1272.25</td>\n",
       "      <td>6.52</td>\n",
       "      <td>835.50</td>\n",
       "      <td>1205.00</td>\n",
       "      <td>1490.00</td>\n",
       "      <td>1110.00</td>\n",
       "      <td>11.15</td>\n",
       "      <td>59.58</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9352</th>\n",
       "      <td>2005-04-04</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>1314.25</td>\n",
       "      <td>13.53</td>\n",
       "      <td>1101.25</td>\n",
       "      <td>538.50</td>\n",
       "      <td>1374.25</td>\n",
       "      <td>1728.50</td>\n",
       "      <td>21.85</td>\n",
       "      <td>29.25</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9353</th>\n",
       "      <td>2005-04-04</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>1162.50</td>\n",
       "      <td>11.36</td>\n",
       "      <td>1027.00</td>\n",
       "      <td>603.75</td>\n",
       "      <td>1263.50</td>\n",
       "      <td>1269.00</td>\n",
       "      <td>24.33</td>\n",
       "      <td>23.72</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9354</th>\n",
       "      <td>2005-04-04</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>1142.00</td>\n",
       "      <td>12.37</td>\n",
       "      <td>1062.50</td>\n",
       "      <td>603.25</td>\n",
       "      <td>1240.75</td>\n",
       "      <td>1092.00</td>\n",
       "      <td>26.90</td>\n",
       "      <td>18.35</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9355</th>\n",
       "      <td>2005-04-04</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>1002.50</td>\n",
       "      <td>9.55</td>\n",
       "      <td>960.50</td>\n",
       "      <td>701.50</td>\n",
       "      <td>1041.00</td>\n",
       "      <td>769.75</td>\n",
       "      <td>28.32</td>\n",
       "      <td>13.55</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>2005-04-04</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>1070.75</td>\n",
       "      <td>11.93</td>\n",
       "      <td>1047.25</td>\n",
       "      <td>654.00</td>\n",
       "      <td>1128.50</td>\n",
       "      <td>816.00</td>\n",
       "      <td>28.50</td>\n",
       "      <td>13.12</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8991 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date      Time  PT08.S1(CO)  C6H6(GT)  PT08.S2(NMHC)  PT08.S3(NOx)  \\\n",
       "0    2004-03-10  18:00:00      1360.00     11.88        1045.50       1056.25   \n",
       "1    2004-03-10  19:00:00      1292.25      9.40         954.75       1173.75   \n",
       "2    2004-03-10  20:00:00      1402.00      9.00         939.25       1140.00   \n",
       "3    2004-03-10  21:00:00      1375.50      9.23         948.25       1092.00   \n",
       "4    2004-03-10  22:00:00      1272.25      6.52         835.50       1205.00   \n",
       "...         ...       ...          ...       ...            ...           ...   \n",
       "9352 2005-04-04  10:00:00      1314.25     13.53        1101.25        538.50   \n",
       "9353 2005-04-04  11:00:00      1162.50     11.36        1027.00        603.75   \n",
       "9354 2005-04-04  12:00:00      1142.00     12.37        1062.50        603.25   \n",
       "9355 2005-04-04  13:00:00      1002.50      9.55         960.50        701.50   \n",
       "9356 2005-04-04  14:00:00      1070.75     11.93        1047.25        654.00   \n",
       "\n",
       "      PT08.S4(NO2)  PT08.S5(O3)      T     RH    AH  \n",
       "0          1692.00      1267.50  13.60  48.88  0.76  \n",
       "1          1558.75       972.25  13.30  47.70  0.73  \n",
       "2          1554.50      1074.00  11.90  53.98  0.75  \n",
       "3          1583.75      1203.25  11.00  60.00  0.79  \n",
       "4          1490.00      1110.00  11.15  59.58  0.79  \n",
       "...            ...          ...    ...    ...   ...  \n",
       "9352       1374.25      1728.50  21.85  29.25  0.76  \n",
       "9353       1263.50      1269.00  24.33  23.72  0.71  \n",
       "9354       1240.75      1092.00  26.90  18.35  0.64  \n",
       "9355       1041.00       769.75  28.32  13.55  0.51  \n",
       "9356       1128.50       816.00  28.50  13.12  0.50  \n",
       "\n",
       "[8991 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8991, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date              383\n",
       "Time               24\n",
       "PT08.S1(CO)      3245\n",
       "C6H6(GT)         3772\n",
       "PT08.S2(NMHC)    3772\n",
       "PT08.S3(NOx)     3518\n",
       "PT08.S4(NO2)     4407\n",
       "PT08.S5(O3)      4678\n",
       "T                3367\n",
       "RH               4902\n",
       "AH               8987\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8991, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date             datetime64[ns]\n",
       "Time                     object\n",
       "PT08.S1(CO)             float64\n",
       "C6H6(GT)                float64\n",
       "PT08.S2(NMHC)           float64\n",
       "PT08.S3(NOx)            float64\n",
       "PT08.S4(NO2)            float64\n",
       "PT08.S5(O3)             float64\n",
       "T                       float64\n",
       "RH                      float64\n",
       "AH                      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"Date\"]=df2.Date.dt.month.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>1360.00</td>\n",
       "      <td>11.88</td>\n",
       "      <td>1045.50</td>\n",
       "      <td>1056.25</td>\n",
       "      <td>1692.00</td>\n",
       "      <td>1267.50</td>\n",
       "      <td>13.60</td>\n",
       "      <td>48.88</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>1292.25</td>\n",
       "      <td>9.40</td>\n",
       "      <td>954.75</td>\n",
       "      <td>1173.75</td>\n",
       "      <td>1558.75</td>\n",
       "      <td>972.25</td>\n",
       "      <td>13.30</td>\n",
       "      <td>47.70</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>1402.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>939.25</td>\n",
       "      <td>1140.00</td>\n",
       "      <td>1554.50</td>\n",
       "      <td>1074.00</td>\n",
       "      <td>11.90</td>\n",
       "      <td>53.98</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>1375.50</td>\n",
       "      <td>9.23</td>\n",
       "      <td>948.25</td>\n",
       "      <td>1092.00</td>\n",
       "      <td>1583.75</td>\n",
       "      <td>1203.25</td>\n",
       "      <td>11.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>1272.25</td>\n",
       "      <td>6.52</td>\n",
       "      <td>835.50</td>\n",
       "      <td>1205.00</td>\n",
       "      <td>1490.00</td>\n",
       "      <td>1110.00</td>\n",
       "      <td>11.15</td>\n",
       "      <td>59.58</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Date      Time  PT08.S1(CO)  C6H6(GT)  PT08.S2(NMHC)  PT08.S3(NOx)  \\\n",
       "0   3.0  18:00:00      1360.00     11.88        1045.50       1056.25   \n",
       "1   3.0  19:00:00      1292.25      9.40         954.75       1173.75   \n",
       "2   3.0  20:00:00      1402.00      9.00         939.25       1140.00   \n",
       "3   3.0  21:00:00      1375.50      9.23         948.25       1092.00   \n",
       "4   3.0  22:00:00      1272.25      6.52         835.50       1205.00   \n",
       "\n",
       "   PT08.S4(NO2)  PT08.S5(O3)      T     RH    AH  \n",
       "0       1692.00      1267.50  13.60  48.88  0.76  \n",
       "1       1558.75       972.25  13.30  47.70  0.73  \n",
       "2       1554.50      1074.00  11.90  53.98  0.75  \n",
       "3       1583.75      1203.25  11.00  60.00  0.79  \n",
       "4       1490.00      1110.00  11.15  59.58  0.79  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"Time\"]=pd.to_datetime(df2[\"Time\"],format=\"%H:%M:%S\").dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"Time\"]=df2[\"Time\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1360.00</td>\n",
       "      <td>11.88</td>\n",
       "      <td>1045.50</td>\n",
       "      <td>1056.25</td>\n",
       "      <td>1692.00</td>\n",
       "      <td>1267.50</td>\n",
       "      <td>13.60</td>\n",
       "      <td>48.88</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1292.25</td>\n",
       "      <td>9.40</td>\n",
       "      <td>954.75</td>\n",
       "      <td>1173.75</td>\n",
       "      <td>1558.75</td>\n",
       "      <td>972.25</td>\n",
       "      <td>13.30</td>\n",
       "      <td>47.70</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1402.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>939.25</td>\n",
       "      <td>1140.00</td>\n",
       "      <td>1554.50</td>\n",
       "      <td>1074.00</td>\n",
       "      <td>11.90</td>\n",
       "      <td>53.98</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1375.50</td>\n",
       "      <td>9.23</td>\n",
       "      <td>948.25</td>\n",
       "      <td>1092.00</td>\n",
       "      <td>1583.75</td>\n",
       "      <td>1203.25</td>\n",
       "      <td>11.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1272.25</td>\n",
       "      <td>6.52</td>\n",
       "      <td>835.50</td>\n",
       "      <td>1205.00</td>\n",
       "      <td>1490.00</td>\n",
       "      <td>1110.00</td>\n",
       "      <td>11.15</td>\n",
       "      <td>59.58</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Date  Time  PT08.S1(CO)  C6H6(GT)  PT08.S2(NMHC)  PT08.S3(NOx)  \\\n",
       "0   3.0  18.0      1360.00     11.88        1045.50       1056.25   \n",
       "1   3.0  19.0      1292.25      9.40         954.75       1173.75   \n",
       "2   3.0  20.0      1402.00      9.00         939.25       1140.00   \n",
       "3   3.0  21.0      1375.50      9.23         948.25       1092.00   \n",
       "4   3.0  22.0      1272.25      6.52         835.50       1205.00   \n",
       "\n",
       "   PT08.S4(NO2)  PT08.S5(O3)      T     RH    AH  \n",
       "0       1692.00      1267.50  13.60  48.88  0.76  \n",
       "1       1558.75       972.25  13.30  47.70  0.73  \n",
       "2       1554.50      1074.00  11.90  53.98  0.75  \n",
       "3       1583.75      1203.25  11.00  60.00  0.79  \n",
       "4       1490.00      1110.00  11.15  59.58  0.79  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df2[\"RH\"].to_numpy()\n",
    "x=df2.drop(\"RH\",axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.00000000e+00, 1.80000000e+01, 1.36000000e+03, ...,\n",
       "        1.26750000e+03, 1.35999999e+01, 7.57753825e-01],\n",
       "       [3.00000000e+00, 1.90000000e+01, 1.29225000e+03, ...,\n",
       "        9.72250000e+02, 1.33000000e+01, 7.25487449e-01],\n",
       "       [3.00000000e+00, 2.00000000e+01, 1.40200000e+03, ...,\n",
       "        1.07400000e+03, 1.19000001e+01, 7.50239067e-01],\n",
       "       ...,\n",
       "       [4.00000000e+00, 1.20000000e+01, 1.14200000e+03, ...,\n",
       "        1.09200000e+03, 2.68999996e+01, 6.40648773e-01],\n",
       "       [4.00000000e+00, 1.30000000e+01, 1.00250000e+03, ...,\n",
       "        7.69750000e+02, 2.83249998e+01, 5.13865916e-01],\n",
       "       [4.00000000e+00, 1.40000000e+01, 1.07075000e+03, ...,\n",
       "        8.16000000e+02, 2.85000005e+01, 5.02803706e-01]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7192, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8991 entries, 0 to 9356\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Date           8991 non-null   float64\n",
      " 1   Time           8991 non-null   float64\n",
      " 2   PT08.S1(CO)    8991 non-null   float64\n",
      " 3   C6H6(GT)       8991 non-null   float64\n",
      " 4   PT08.S2(NMHC)  8991 non-null   float64\n",
      " 5   PT08.S3(NOx)   8991 non-null   float64\n",
      " 6   PT08.S4(NO2)   8991 non-null   float64\n",
      " 7   PT08.S5(O3)    8991 non-null   float64\n",
      " 8   T              8991 non-null   float64\n",
      " 9   RH             8991 non-null   float64\n",
      " 10  AH             8991 non-null   float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 842.9 KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()\n",
    "input_sh=[x_train.shape[1]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 1 : NODES : (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(10,)),\n",
    "    tf.keras.layers.Dense(units=1,activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 12        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70\n",
      "Trainable params: 70\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "225/225 [==============================] - 1s 1ms/step - loss: 3550.8179\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 2579.4307\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 2528.0161\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 2456.8755\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 2206.7703\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 797.9853\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 305.3106\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 243.9139\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 223.5549\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 210.5143\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 200.6780\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 192.3778\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 183.3196\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 176.6643\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 167.8437\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 159.0802\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 152.9819\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 142.2166\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 135.5344\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 126.5859\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 117.2596\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 112.0875\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 103.3428\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 98.8133\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 97.3950\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 90.9762\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 88.0373\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 87.5569\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 84.7857\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 85.1986\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 82.5309\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 80.7101\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 78.4771\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 79.9824\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 77.5377\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 77.2062\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 74.9401\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 76.0278\n",
      "Epoch 39/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 75.5212\n",
      "Epoch 40/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 72.1025\n",
      "Epoch 41/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 72.8900\n",
      "Epoch 42/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 69.2533\n",
      "Epoch 43/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 68.4476\n",
      "Epoch 44/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 67.8871\n",
      "Epoch 45/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 69.3467\n",
      "Epoch 46/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 68.2595\n",
      "Epoch 47/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 66.2717\n",
      "Epoch 48/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 66.7295\n",
      "Epoch 49/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 66.5766\n",
      "Epoch 50/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 64.5216\n",
      "Epoch 51/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 63.8314\n",
      "Epoch 52/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 63.4333\n",
      "Epoch 53/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 62.1389\n",
      "Epoch 54/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 63.5458\n",
      "Epoch 55/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 62.4638\n",
      "Epoch 56/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 62.8902\n",
      "Epoch 57/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 60.0185\n",
      "Epoch 58/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 60.4910\n",
      "Epoch 59/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 59.4685\n",
      "Epoch 60/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 59.9350\n",
      "Epoch 61/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 56.9591\n",
      "Epoch 62/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 58.7451\n",
      "Epoch 63/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 57.9437\n",
      "Epoch 64/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 56.5175\n",
      "Epoch 65/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 56.3138\n",
      "Epoch 66/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 55.5427\n",
      "Epoch 67/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 55.2443\n",
      "Epoch 68/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 55.2755\n",
      "Epoch 69/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 54.7044\n",
      "Epoch 70/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 53.0977\n",
      "Epoch 71/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 55.1319\n",
      "Epoch 72/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 54.1094\n",
      "Epoch 73/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 52.7841\n",
      "Epoch 74/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 51.8669\n",
      "Epoch 75/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 54.4145\n",
      "Epoch 76/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 51.7999\n",
      "Epoch 77/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 49.5454\n",
      "Epoch 78/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 54.5091\n",
      "Epoch 79/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 49.7677\n",
      "Epoch 80/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 50.0652\n",
      "Epoch 81/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 49.5004\n",
      "Epoch 82/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 49.0975\n",
      "Epoch 83/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 48.6119\n",
      "Epoch 84/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 49.1920\n",
      "Epoch 85/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 49.3567\n",
      "Epoch 86/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 48.0361\n",
      "Epoch 87/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 46.3754\n",
      "Epoch 88/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 47.0214\n",
      "Epoch 89/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 47.1512\n",
      "Epoch 90/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 47.1205\n",
      "Epoch 91/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 45.3089\n",
      "Epoch 92/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 48.4285\n",
      "Epoch 93/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 46.1239\n",
      "Epoch 94/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 45.8799\n",
      "Epoch 95/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 46.1855\n",
      "Epoch 96/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 45.8707\n",
      "Epoch 97/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 45.5611\n",
      "Epoch 98/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 44.0447\n",
      "Epoch 99/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 44.1719\n",
      "Epoch 100/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 46.0047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c307e4d60>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(optimizer='adam',loss=tf.keras.losses.mean_squared_error)\n",
    "model1.summary()\n",
    "model1.fit(x_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 1ms/step - loss: 42.9836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42.983585357666016"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(x_test,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 1 : TEST CASE LOSSES =  42.9836"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 2 : NODES = (5,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(10,)),\n",
    "    tf.keras.layers.Dense(units=5,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=2,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1,activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 12        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70\n",
      "Trainable params: 70\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "225/225 [==============================] - 1s 1ms/step - loss: 54.1108\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 53.8608\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 54.6014\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 53.2273\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 52.7411\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 53.4745\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 52.2122\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 52.6194\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 52.2181\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 51.8802\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 51.7225\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 52.0802\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 52.5570\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 51.0917\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 51.3226\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 51.5108\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 51.7317\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 50.9643\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 51.2369\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 50.9906\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 50.9624\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 50.5007\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 51.5501\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 50.5517\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 50.7453\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 50.5697\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 50.6675\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 50.0002\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 50.0579\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 49.8022\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 49.6605\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 49.3976\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 49.5544\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 48.9760\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 49.6603\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 51.0288\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 49.8723\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 49.0462\n",
      "Epoch 39/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 48.9798\n",
      "Epoch 40/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 50.0222\n",
      "Epoch 41/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 48.5563\n",
      "Epoch 42/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 48.9668\n",
      "Epoch 43/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 48.2569\n",
      "Epoch 44/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 48.1261\n",
      "Epoch 45/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 48.5030\n",
      "Epoch 46/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 48.6388\n",
      "Epoch 47/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 48.1148\n",
      "Epoch 48/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 48.8353\n",
      "Epoch 49/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 47.9395\n",
      "Epoch 50/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 48.1827\n",
      "Epoch 51/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 47.8119\n",
      "Epoch 52/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 47.5942\n",
      "Epoch 53/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 47.7587\n",
      "Epoch 54/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 47.3495\n",
      "Epoch 55/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 47.3435\n",
      "Epoch 56/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 47.0926\n",
      "Epoch 57/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 47.3673\n",
      "Epoch 58/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 46.8048\n",
      "Epoch 59/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 46.5705\n",
      "Epoch 60/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 47.2396\n",
      "Epoch 61/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 46.4757\n",
      "Epoch 62/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 46.7360\n",
      "Epoch 63/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 46.2090\n",
      "Epoch 64/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 45.8147\n",
      "Epoch 65/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 46.7321\n",
      "Epoch 66/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 45.4958\n",
      "Epoch 67/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 45.7710\n",
      "Epoch 68/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 45.8476\n",
      "Epoch 69/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 45.6527\n",
      "Epoch 70/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 45.3386\n",
      "Epoch 71/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 45.7322\n",
      "Epoch 72/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 45.7820\n",
      "Epoch 73/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 45.4954\n",
      "Epoch 74/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 45.2003\n",
      "Epoch 75/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 45.9938\n",
      "Epoch 76/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 45.1462\n",
      "Epoch 77/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 45.4922\n",
      "Epoch 78/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 44.9927\n",
      "Epoch 79/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 44.2077\n",
      "Epoch 80/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 44.9668\n",
      "Epoch 81/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 44.5905\n",
      "Epoch 82/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 44.0907\n",
      "Epoch 83/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 44.8718\n",
      "Epoch 84/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 44.1189\n",
      "Epoch 85/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 44.4889\n",
      "Epoch 86/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 43.6261\n",
      "Epoch 87/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 43.6488\n",
      "Epoch 88/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 43.3831\n",
      "Epoch 89/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 44.1442\n",
      "Epoch 90/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 43.4476\n",
      "Epoch 91/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 43.7619\n",
      "Epoch 92/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 42.8615\n",
      "Epoch 93/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 42.6829\n",
      "Epoch 94/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 44.4973\n",
      "Epoch 95/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 43.0501\n",
      "Epoch 96/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 42.4123\n",
      "Epoch 97/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 42.4276\n",
      "Epoch 98/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 42.6745\n",
      "Epoch 99/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 42.0725\n",
      "Epoch 100/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 42.3363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c2b1e79d0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(optimizer='adam',loss=tf.keras.losses.mean_squared_error)\n",
    "model2.summary()\n",
    "model2.fit(x_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 1ms/step - loss: 48.1416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48.141597747802734"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x_test,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 2 : TEST LOSS = 48.1416"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 3 : NODES = (3,7,4,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(10,)),\n",
    "    tf.keras.layers.Dense(units=3,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=7,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=4,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=2,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1,activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 3)                 33        \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 7)                 28        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 4)                 32        \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106\n",
      "Trainable params: 106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "225/225 [==============================] - 1s 1ms/step - loss: 73.6159\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 72.1992\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 73.7427\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 72.0923\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 72.6115\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 70.5149\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 69.2572\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 69.2392\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 70.5905\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 68.6198\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 68.8409\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 68.8767\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 67.6949\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 67.6994\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 67.2068\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 67.7762\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 65.8719\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 66.4126\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 66.0531\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 65.1732\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 66.2251\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 67.9677\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 64.9473\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 65.9671\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 64.2672\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 66.0759\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 63.4355\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 64.2210\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 65.0229\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 63.8617\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 61.9885\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 62.7524\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 63.9434\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 62.0016\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 62.7916\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 61.0757\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 60.7804\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 61.3146\n",
      "Epoch 39/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 60.5197\n",
      "Epoch 40/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 61.3415\n",
      "Epoch 41/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 61.4249\n",
      "Epoch 42/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 59.8860\n",
      "Epoch 43/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 61.3191\n",
      "Epoch 44/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 61.2509\n",
      "Epoch 45/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 59.8267\n",
      "Epoch 46/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 60.0346\n",
      "Epoch 47/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 59.2023\n",
      "Epoch 48/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 57.9349\n",
      "Epoch 49/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 59.6832\n",
      "Epoch 50/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 59.7393\n",
      "Epoch 51/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 57.9809\n",
      "Epoch 52/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 57.3771\n",
      "Epoch 53/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 61.1710\n",
      "Epoch 54/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 58.8634\n",
      "Epoch 55/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 58.2478\n",
      "Epoch 56/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 58.2534\n",
      "Epoch 57/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 58.3158\n",
      "Epoch 58/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 58.0115\n",
      "Epoch 59/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 56.6024\n",
      "Epoch 60/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 56.6542\n",
      "Epoch 61/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 55.9468\n",
      "Epoch 62/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 55.5846\n",
      "Epoch 63/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 56.7003\n",
      "Epoch 64/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 55.5465\n",
      "Epoch 65/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 56.4481\n",
      "Epoch 66/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 55.7714\n",
      "Epoch 67/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 57.4667\n",
      "Epoch 68/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 57.0493\n",
      "Epoch 69/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 54.7293\n",
      "Epoch 70/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 56.2837\n",
      "Epoch 71/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 55.0873\n",
      "Epoch 72/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 53.7854\n",
      "Epoch 73/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 54.3302\n",
      "Epoch 74/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 54.0768\n",
      "Epoch 75/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 54.1376\n",
      "Epoch 76/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 55.1057\n",
      "Epoch 77/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 53.6828\n",
      "Epoch 78/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 55.1880\n",
      "Epoch 79/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 54.0084\n",
      "Epoch 80/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 53.6761\n",
      "Epoch 81/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 52.7563\n",
      "Epoch 82/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 52.3780\n",
      "Epoch 83/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 53.1715\n",
      "Epoch 84/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 52.7213\n",
      "Epoch 85/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 52.5496\n",
      "Epoch 86/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 52.7732\n",
      "Epoch 87/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 52.5064\n",
      "Epoch 88/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 51.2690\n",
      "Epoch 89/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 51.2257\n",
      "Epoch 90/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 51.3599\n",
      "Epoch 91/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 51.1554\n",
      "Epoch 92/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 50.6859\n",
      "Epoch 93/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 51.5208\n",
      "Epoch 94/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 50.3442\n",
      "Epoch 95/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 52.4735\n",
      "Epoch 96/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 50.5397\n",
      "Epoch 97/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 50.0084\n",
      "Epoch 98/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 50.5088\n",
      "Epoch 99/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 50.1272\n",
      "Epoch 100/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 48.1397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c32c99300>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.compile(optimizer='adam',loss=tf.keras.losses.mean_squared_error)\n",
    "model3.summary()\n",
    "model3.fit(x_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step - loss: 49.9374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49.93735122680664"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(x_test,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 3 : TEST LOSS = 49.9374"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 4 : NODES=(1,2,4,8,16,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4=tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(10,)),\n",
    "    tf.keras.layers.Dense(units=1,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=2,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=4,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=8,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=16,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1,activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 4)                 8         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 8)                 40        \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 3)                 27        \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 9)                 36        \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 132\n",
      "Trainable params: 132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "225/225 [==============================] - 1s 1ms/step - loss: 2681.1421\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 2385.1086\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 1798.3523\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 1152.2559\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 698.5396\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 444.3087\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 337.3172\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 305.7342\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 299.1000\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0811\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9277\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9344\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9072\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9445\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9167\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9341\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9405\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9663\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9495\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9504\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9512\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9700\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9561\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9969\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9583\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9857\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9551\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9590\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9665\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9767\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9830\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.0187\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9939\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9877\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1133\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0008\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9189\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9342\n",
      "Epoch 39/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9607\n",
      "Epoch 40/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9732\n",
      "Epoch 41/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.8768\n",
      "Epoch 42/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0642\n",
      "Epoch 43/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0501\n",
      "Epoch 44/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0105\n",
      "Epoch 45/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0260\n",
      "Epoch 46/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9488\n",
      "Epoch 47/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9685\n",
      "Epoch 48/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.0695\n",
      "Epoch 49/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9449\n",
      "Epoch 50/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9625\n",
      "Epoch 51/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 297.9568\n",
      "Epoch 52/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.1128\n",
      "Epoch 53/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 297.9520\n",
      "Epoch 54/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.0442\n",
      "Epoch 55/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.0043\n",
      "Epoch 56/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 297.9525\n",
      "Epoch 57/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 297.9850\n",
      "Epoch 58/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 297.9590\n",
      "Epoch 59/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 297.9174\n",
      "Epoch 60/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9727\n",
      "Epoch 61/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9912\n",
      "Epoch 62/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9502\n",
      "Epoch 63/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 297.9589\n",
      "Epoch 64/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9102\n",
      "Epoch 65/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.0079\n",
      "Epoch 66/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 297.9413\n",
      "Epoch 67/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9454\n",
      "Epoch 68/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9579\n",
      "Epoch 69/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9586\n",
      "Epoch 70/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9948\n",
      "Epoch 71/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9147\n",
      "Epoch 72/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9067\n",
      "Epoch 73/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0333\n",
      "Epoch 74/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9103\n",
      "Epoch 75/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0198\n",
      "Epoch 76/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9618\n",
      "Epoch 77/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 297.9474\n",
      "Epoch 78/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0207\n",
      "Epoch 79/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0735\n",
      "Epoch 80/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0179\n",
      "Epoch 81/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9881\n",
      "Epoch 82/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.8763\n",
      "Epoch 83/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9951\n",
      "Epoch 84/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 297.9645\n",
      "Epoch 85/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9804\n",
      "Epoch 86/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9753\n",
      "Epoch 87/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0267\n",
      "Epoch 88/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0145\n",
      "Epoch 89/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0233\n",
      "Epoch 90/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9162\n",
      "Epoch 91/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.1198\n",
      "Epoch 92/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9622\n",
      "Epoch 93/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9903\n",
      "Epoch 94/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9807\n",
      "Epoch 95/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9238\n",
      "Epoch 96/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0005\n",
      "Epoch 97/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9441\n",
      "Epoch 98/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.0447\n",
      "Epoch 99/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.8908\n",
      "Epoch 100/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c35dcf610>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.compile(optimizer='adam',loss=tf.keras.losses.mean_squared_error)\n",
    "model4.summary()\n",
    "model4.fit(x_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 1ms/step - loss: 307.6049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "307.60491943359375"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.evaluate(x_test,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 4 : TEST LOSS = 307.6049"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 5 : NODES = (1,4,8,3,9,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5=tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(10,)),\n",
    "    tf.keras.layers.Dense(units=1,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=4,activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(units=8,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=3,activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(units=9,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1,activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 4)                 8         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 8)                 40        \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 3)                 27        \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 9)                 36        \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 132\n",
      "Trainable params: 132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 298.0580\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 298.0947\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.2108\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0966\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1584\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0330\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1002\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0929\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1823\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.1515\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.4060\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9778\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.2086\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1171\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1273\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0933\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.0746\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 297.8932\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.3506\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.3032\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.0970\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.1020\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1151\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0158\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0983\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0888\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0652\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0198\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.0903\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0216\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.1038\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.1653\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.0097\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.1888\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.0917\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0958\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1182\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.3460\n",
      "Epoch 39/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0953\n",
      "Epoch 40/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1209\n",
      "Epoch 41/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9703\n",
      "Epoch 42/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1714\n",
      "Epoch 43/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.1255\n",
      "Epoch 44/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.2770\n",
      "Epoch 45/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1582\n",
      "Epoch 46/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.2091\n",
      "Epoch 47/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0701\n",
      "Epoch 48/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0990\n",
      "Epoch 49/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1317\n",
      "Epoch 50/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.0905\n",
      "Epoch 51/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1948\n",
      "Epoch 52/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1556\n",
      "Epoch 53/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.1906\n",
      "Epoch 54/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0353\n",
      "Epoch 55/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.2560\n",
      "Epoch 56/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0269\n",
      "Epoch 57/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.2956\n",
      "Epoch 58/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0643\n",
      "Epoch 59/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1779\n",
      "Epoch 60/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0362\n",
      "Epoch 61/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.2291\n",
      "Epoch 62/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1807\n",
      "Epoch 63/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1223\n",
      "Epoch 64/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0429\n",
      "Epoch 65/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.1535\n",
      "Epoch 66/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0750\n",
      "Epoch 67/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0892\n",
      "Epoch 68/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0948\n",
      "Epoch 69/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.2164\n",
      "Epoch 70/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1595\n",
      "Epoch 71/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1068\n",
      "Epoch 72/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.2243\n",
      "Epoch 73/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1186\n",
      "Epoch 74/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.2149\n",
      "Epoch 75/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.3850\n",
      "Epoch 76/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1200\n",
      "Epoch 77/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9792\n",
      "Epoch 78/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0232\n",
      "Epoch 79/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0199\n",
      "Epoch 80/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.0382\n",
      "Epoch 81/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.2582\n",
      "Epoch 82/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.2031\n",
      "Epoch 83/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9455\n",
      "Epoch 84/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1471\n",
      "Epoch 85/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1040\n",
      "Epoch 86/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.2328\n",
      "Epoch 87/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.1677\n",
      "Epoch 88/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0403\n",
      "Epoch 89/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 297.9214\n",
      "Epoch 90/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0137\n",
      "Epoch 91/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1098\n",
      "Epoch 92/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1092\n",
      "Epoch 93/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.2180\n",
      "Epoch 94/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.4004\n",
      "Epoch 95/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.0016\n",
      "Epoch 96/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.0494\n",
      "Epoch 97/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.2180\n",
      "Epoch 98/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.3106\n",
      "Epoch 99/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 298.1833\n",
      "Epoch 100/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 298.3762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c3a4cd570>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.compile(optimizer=tf.keras.optimizers.Adam(0.005),loss=tf.keras.losses.mean_squared_error)\n",
    "model5.summary()\n",
    "model5.fit(x_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step - loss: 307.8592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "307.8592224121094"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.evaluate(x_test,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL5 : TEST LOSS = 307.8592"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL6 : NODES = (128,64,32,16,8,4,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6=tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(10,)),\n",
    "    tf.keras.layers.Dense(units=128,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=32,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=16,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=8,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=4,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=8,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=8,activation='linear'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_44 (Dense)            (None, 128)               1408      \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 8)                 40        \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,556\n",
      "Trainable params: 12,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "225/225 [==============================] - 2s 2ms/step - loss: 299.7521\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.7815\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 301.8061\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 299.6342\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.2237\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.0143\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.3152\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.4727\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 301.5222\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.2181\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.5836\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.5897\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.3079\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 300.3852\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.4692\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 300.8145\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.9497\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.6375\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.1322\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 301.0770\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.3073\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.0098\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.1357\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 301.0878\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.0333\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 302.6823\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 302.0474\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.3528\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.4216\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 299.4709\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.5189\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.6848\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.9241\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.2235\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.4938\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.7623\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.8807\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.8429\n",
      "Epoch 39/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.2610\n",
      "Epoch 40/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.9849\n",
      "Epoch 41/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.4561\n",
      "Epoch 42/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.9471\n",
      "Epoch 43/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.0511\n",
      "Epoch 44/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.9602\n",
      "Epoch 45/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.0878\n",
      "Epoch 46/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.3960\n",
      "Epoch 47/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.9033\n",
      "Epoch 48/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.1154\n",
      "Epoch 49/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.8335\n",
      "Epoch 50/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 299.6667\n",
      "Epoch 51/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.0244\n",
      "Epoch 52/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 299.4965\n",
      "Epoch 53/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.8082\n",
      "Epoch 54/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.7319\n",
      "Epoch 55/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.3740\n",
      "Epoch 56/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.2681\n",
      "Epoch 57/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.6666\n",
      "Epoch 58/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.0305\n",
      "Epoch 59/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.9619\n",
      "Epoch 60/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 301.1503\n",
      "Epoch 61/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 301.1347\n",
      "Epoch 62/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.8728\n",
      "Epoch 63/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.8456\n",
      "Epoch 64/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.7357\n",
      "Epoch 65/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 301.5106\n",
      "Epoch 66/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.1394\n",
      "Epoch 67/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.7365\n",
      "Epoch 68/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.9341\n",
      "Epoch 69/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.1277\n",
      "Epoch 70/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.7944\n",
      "Epoch 71/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 301.2022\n",
      "Epoch 72/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.2365\n",
      "Epoch 73/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.5226\n",
      "Epoch 74/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.4955\n",
      "Epoch 75/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.1195\n",
      "Epoch 76/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.0112\n",
      "Epoch 77/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.7485\n",
      "Epoch 78/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 301.0134\n",
      "Epoch 79/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.1584\n",
      "Epoch 80/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.6830\n",
      "Epoch 81/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.4617\n",
      "Epoch 82/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.4261\n",
      "Epoch 83/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.9880\n",
      "Epoch 84/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.0564\n",
      "Epoch 85/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.5905\n",
      "Epoch 86/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.5128\n",
      "Epoch 87/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.7245\n",
      "Epoch 88/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.9022\n",
      "Epoch 89/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 299.4940\n",
      "Epoch 90/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 300.1510\n",
      "Epoch 91/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.7527\n",
      "Epoch 92/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.9683\n",
      "Epoch 93/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.8708\n",
      "Epoch 94/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.9786\n",
      "Epoch 95/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 300.5569\n",
      "Epoch 96/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 300.2975\n",
      "Epoch 97/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.7810\n",
      "Epoch 98/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 299.7875\n",
      "Epoch 99/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 299.9153\n",
      "Epoch 100/100\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 300.5798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c307e4040>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.compile(optimizer=tf.keras.optimizers.Adam(0.01),loss=tf.keras.losses.mean_squared_error)\n",
    "model6.summary()\n",
    "model6.fit(x_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 1ms/step - loss: 308.3752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "308.3752136230469"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.evaluate(x_test,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 7 : NODES = (70,32,87,13,22,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7=tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(10,)),\n",
    "    tf.keras.layers.Dense(units=70,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=32,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=87,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=13,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=22,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1,activation='linear')\n",
    "  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_52 (Dense)            (None, 70)                770       \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 32)                2272      \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 87)                2871      \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 13)                1144      \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 22)                308       \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 1)                 23        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,388\n",
      "Trainable params: 7,388\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "225/225 [==============================] - 1s 1ms/step - loss: 377.4623\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 215.5998\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 144.5864\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 124.8795\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 104.3241\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 99.9613\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 82.0981\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 85.7190\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 76.2751\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 68.1306\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 62.9586\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 60.2546\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 56.5908\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 51.6506\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 48.9415\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 49.5487\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 45.8184\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 47.0653\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 40.5194\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 41.0761\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 36.5776\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 38.3882\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 36.8894\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 43.6960\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 30.2948\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 37.6226\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 27.9125\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 36.1728\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 39.7004\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 34.6192\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 32.8288\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 31.7585\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 33.6751\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 30.7925\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 35.6119\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 28.4245\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 26.5975\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 35.1086\n",
      "Epoch 39/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 29.4585\n",
      "Epoch 40/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 33.2193\n",
      "Epoch 41/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 27.4648\n",
      "Epoch 42/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 32.4822\n",
      "Epoch 43/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 36.5492\n",
      "Epoch 44/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 23.5009\n",
      "Epoch 45/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 24.6938\n",
      "Epoch 46/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 27.6879\n",
      "Epoch 47/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 28.1324\n",
      "Epoch 48/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 24.2757\n",
      "Epoch 49/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 27.4736\n",
      "Epoch 50/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 28.8042\n",
      "Epoch 51/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 26.8682\n",
      "Epoch 52/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 24.7698\n",
      "Epoch 53/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 32.7956\n",
      "Epoch 54/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 25.9038\n",
      "Epoch 55/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 24.8500\n",
      "Epoch 56/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 24.2375\n",
      "Epoch 57/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 28.2387\n",
      "Epoch 58/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 23.0374\n",
      "Epoch 59/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 28.7432\n",
      "Epoch 60/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 29.9541\n",
      "Epoch 61/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 23.5653\n",
      "Epoch 62/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 24.0877\n",
      "Epoch 63/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 27.0249\n",
      "Epoch 64/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 24.9697\n",
      "Epoch 65/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 26.2377\n",
      "Epoch 66/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 24.8568\n",
      "Epoch 67/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 21.4981\n",
      "Epoch 68/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 41.0710\n",
      "Epoch 69/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 23.9585\n",
      "Epoch 70/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 22.7752\n",
      "Epoch 71/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 23.3765\n",
      "Epoch 72/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 20.1392\n",
      "Epoch 73/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 23.2910\n",
      "Epoch 74/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 27.2652\n",
      "Epoch 75/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 23.3232\n",
      "Epoch 76/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 20.3257\n",
      "Epoch 77/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 21.4828\n",
      "Epoch 78/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 18.5836\n",
      "Epoch 79/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 24.5963\n",
      "Epoch 80/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 21.6065\n",
      "Epoch 81/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 20.9309\n",
      "Epoch 82/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 20.4313\n",
      "Epoch 83/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 25.1484\n",
      "Epoch 84/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 22.7663\n",
      "Epoch 85/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 17.7698\n",
      "Epoch 86/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 21.9650\n",
      "Epoch 87/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 20.7125\n",
      "Epoch 88/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 21.0129\n",
      "Epoch 89/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 18.1835\n",
      "Epoch 90/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 26.3643\n",
      "Epoch 91/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 23.6540\n",
      "Epoch 92/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 18.6163\n",
      "Epoch 93/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 17.2790\n",
      "Epoch 94/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 22.1528\n",
      "Epoch 95/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 20.7313\n",
      "Epoch 96/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 19.5988\n",
      "Epoch 97/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 19.3768\n",
      "Epoch 98/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 22.1958\n",
      "Epoch 99/100\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 19.3502\n",
      "Epoch 100/100\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 25.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c3fe18e50>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.compile(optimizer=tf.keras.optimizers.Adam(0.01),loss=tf.keras.losses.mean_squared_error)\n",
    "model7.summary()\n",
    "model7.fit(x_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 1ms/step - loss: 20.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.98752212524414"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.evaluate(x_test,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION : Minimum Loss and Error is in MODEL-7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fbc768028c3e6ead51d9a200ddcb2ec858ae62844dcd1994729a8279be9b48f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
