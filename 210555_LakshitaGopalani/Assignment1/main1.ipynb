{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjINZlg2y_vJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import linearRegression as lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mnl74RtYmwIW"
      },
      "outputs": [],
      "source": [
        "X = np.array([[2.5, 4.7, 5.2, 7.3, 9.5, 11.5]]).T\n",
        "Y_train = np.array([[5.21, 7.70, 8.30, 11, 14.5, 15]]).T\n",
        "X_train = np.insert(X,0,1,axis=1)\n",
        "\n",
        "X_test = np.array([[3.5, 5, 6, 8, 10]]).T\n",
        "X_test_ = np.insert(X_test,0,1,axis=1)\n",
        "Y_test = np.array([[6.25, 8.2, 9.5, 12.1, 14.7]]).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tluIAe9xuaH8"
      },
      "outputs": [],
      "source": [
        "#Calculating theta and predicted values using Gradient Descent and Normal Equations:\n",
        "\n",
        "theta = lr.fitGD(X_train, Y_train, 0.01, 0, 2, 100)\n",
        "theta_n = lr.fitNormal(X_train, Y_train)\n",
        "\n",
        "Y_pred_train_GD = X_train @ theta\n",
        "Y_pred_train_normal = X_train @ theta_n\n",
        "\n",
        "Y_pred_test_GD = X_test_ @ theta\n",
        "Y_pred_test_normal = X_test_ @ theta_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCMliXc4K4Ke"
      },
      "outputs": [],
      "source": [
        "#Plot of straight lines obtained on training data:\n",
        "\n",
        "plt.scatter(X,Y_train, label = 'Training Data Points', color='black')\n",
        "plt.plot(X, Y_pred_train_GD, label='Gradient Descend', color='blue')\n",
        "plt.plot(X, Y_pred_train_normal, label='Normal Equations', color='orange')\n",
        "plt.legend()\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVJusvBeMfjr"
      },
      "outputs": [],
      "source": [
        "#Predictions using Locally Weighted Regression:\n",
        "\n",
        "Y_pred_lw1 = lr.locallyWeighted(X_train, Y_train, X_test_, 0.01, 0.01, 100)\n",
        "Y_pred_lw2 = lr.locallyWeighted(X_train, Y_train, X_test_, 0.1, 0.01, 100)\n",
        "Y_pred_lw3 = lr.locallyWeighted(X_train, Y_train, X_test_, 1, 0.01, 100)\n",
        "Y_pred_lw4 = lr.locallyWeighted(X_train, Y_train, X_test_, 10, 0.01, 100)\n",
        "Y_pred_lw5 = lr.locallyWeighted(X_train, Y_train, X_test_, 100, 0.01, 100)\n",
        "\n",
        "print(Y_pred_lw1, \"\\n\\n\" , Y_pred_lw2, \"\\n\\n\" , Y_pred_lw3, \"\\n\\n\" , Y_pred_lw4, \"\\n\\n\" , Y_pred_lw5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-dRZBWpZOQL"
      },
      "outputs": [],
      "source": [
        "#Error Analysis for Gradient Descent:\n",
        "\n",
        "J_train = np.zeros((15,1))\n",
        "J_test = np.zeros((15,1))\n",
        "\n",
        "for i in range(1,16):\n",
        "  theta_train = lr.fitGD(X_train, Y_train, 0.01, i, 2, 100)\n",
        "  J_train[i-1] = lr.costFun(theta_train, X_train, Y_train)\n",
        "  J_test[i-1] = lr.costFun(theta_train, X_test_, Y_test)\n",
        "\n",
        "plt.clf()\n",
        "plt.plot(np.linspace(1,15,15),J_train,c='blue',label='Training Data',marker='.')\n",
        "plt.plot(np.linspace(1,15,15),J_test,c='orange',label='Test Data',marker='*')\n",
        "plt.xlabel('Lambda')\n",
        "plt.ylabel('Error / Cost Function')\n",
        "plt.title('Variation of Cost Function with lambda')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WuK_2ELc3vR"
      },
      "outputs": [],
      "source": [
        "#Error Analysis for Locally Weighted:\n",
        "\n",
        "tau = [10**i for i in range(-5, 6)]\n",
        "J_train_lw = []\n",
        "J_test_lw = []\n",
        "\n",
        "for t in tau:  \n",
        "  Y_pred_train_lw = lr.locallyWeighted(X_train, Y_train, X_train, t, 0.01, 100)\n",
        "  Y_pred_test_lw = lr.locallyWeighted(X_train, Y_train, X_test_, t, 0.01, 100)\n",
        "  J_train_lw.append(np.linalg.norm(Y_train.T-Y_pred_train_lw, 2))\n",
        "  J_test_lw.append(np.linalg.norm(Y_test.T-Y_pred_test_lw, 2))\n",
        "\n",
        "plt.plot(np.log10(tau), J_train_lw, c='blue', label='Train', marker='.')\n",
        "plt.plot(np.log10(tau), J_test_lw, c='orange', label='Test', marker='*')\n",
        "plt.xlabel('log(tau)')\n",
        "plt.ylabel('Cost Function')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhJ--9PFRHXv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}